{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "692fc5d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Required Libraries\n",
    "import numpy as np\n",
    "import joblib\n",
    "import torch\n",
    "import torchaudio\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression, Perceptron\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score,\n",
    "    f1_score, roc_auc_score\n",
    ")\n",
    "from tqdm import tqdm\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Preprocessing parameters\n",
    "SAMPLE_RATE = 16000\n",
    "NUM_MFCC = 13\n",
    "DURATION = 3  # seconds\n",
    "MAX_LEN = SAMPLE_RATE * DURATION\n",
    "\n",
    "# MFCC transformation\n",
    "mfcc_transform = torchaudio.transforms.MFCC(\n",
    "    sample_rate=SAMPLE_RATE,\n",
    "    n_mfcc=NUM_MFCC,\n",
    "    melkwargs={\"n_fft\": 400, \"hop_length\": 160, \"n_mels\": 23}\n",
    ")\n",
    "\n",
    "# Dataset Paths (adjust this according to your local paths)\n",
    "bonafide_path = \"D:/Git/Hugging-Face/deepfake_detection_dataset_urdu/Bonafide\"\n",
    "spoofed_tacotron_path = \"D:/Git/Hugging-Face/deepfake_detection_dataset_urdu/Spoofed_Tacotron\"\n",
    "spoofed_tts_path = \"D:/Git/Hugging-Face/deepfake_detection_dataset_urdu/Spoofed_TTS\"\n",
    "\n",
    "# Function to load audio files\n",
    "def load_audio_files(path, label):\n",
    "    audio_files = []\n",
    "    # Walk through all directories and subdirectories\n",
    "    for root, dirs, files in os.walk(path):\n",
    "        for file in files:\n",
    "            # Check if the file is a .wav file\n",
    "            if file.endswith('.wav'):\n",
    "                file_path = os.path.join(root, file)\n",
    "                try:\n",
    "                    waveform, sample_rate = torchaudio.load(file_path)\n",
    "                    audio_files.append((waveform, sample_rate, label))\n",
    "                except Exception as e:\n",
    "                    print(f\"Error loading file {file_path}: {e}\")\n",
    "    return audio_files\n",
    "\n",
    "# Load data from all directories recursively\n",
    "bonafide_data = load_audio_files(bonafide_path, \"Bonafide\")\n",
    "spoofed_tacotron_data = load_audio_files(spoofed_tacotron_path, \"Spoofed\")\n",
    "spoofed_tts_data = load_audio_files(spoofed_tts_path, \"Spoofed\")\n",
    "\n",
    "# Print the total number of files loaded from each folder\n",
    "print(f\"Bonafide data loaded: {len(bonafide_data)} files\")\n",
    "print(f\"Spoofed_Tacotron data loaded: {len(spoofed_tacotron_data)} files\")\n",
    "print(f\"Spoofed_TTS data loaded: {len(spoofed_tts_data)} files\")\n",
    "\n",
    "# Combine all data into one list\n",
    "all_audio_data = bonafide_data + spoofed_tacotron_data + spoofed_tts_data\n",
    "\n",
    "# Check the total number of samples loaded\n",
    "print(f\"Total number of samples loaded: {len(all_audio_data)}\")\n",
    "\n",
    "# Preprocess each audio file and extract MFCC features\n",
    "def preprocess(example):\n",
    "    waveform, sr, label = example\n",
    "    if sr != SAMPLE_RATE:\n",
    "        resampler = torchaudio.transforms.Resample(orig_freq=sr, new_freq=SAMPLE_RATE)\n",
    "        waveform = resampler(waveform)\n",
    "\n",
    "    # Pad or truncate the waveform to fit the desired length\n",
    "    if waveform.shape[1] < MAX_LEN:\n",
    "        pad_len = MAX_LEN - waveform.shape[1]\n",
    "        waveform = torch.nn.functional.pad(waveform, (0, pad_len))\n",
    "    else:\n",
    "        waveform = waveform[:, :MAX_LEN]\n",
    "\n",
    "    mfcc = mfcc_transform(waveform).squeeze().T  # shape: (time_steps, n_mfcc)\n",
    "    return {'features': mfcc.numpy(), 'label': label}\n",
    "\n",
    "# Process dataset and extract features\n",
    "processed_data = [preprocess(example) for example in tqdm(all_audio_data)]\n",
    "\n",
    "# Convert to feature matrix\n",
    "X = np.array([ex['features'].flatten() for ex in processed_data])\n",
    "y = np.array([ex['label'] for ex in processed_data])\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(y)\n",
    "\n",
    "# Model Building\n",
    "print(\"Initializing models...\")\n",
    "svm_model = SVC(kernel='rbf', probability=True)\n",
    "log_model = LogisticRegression(max_iter=2000)\n",
    "perceptron_model = Perceptron(max_iter=1000)\n",
    "dnn_model = MLPClassifier(hidden_layer_sizes=(256, 128), max_iter=200)\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "print(\"Splitting and training...\")\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "# Training each model\n",
    "print(\"Training SVM...\")\n",
    "svm_model.fit(X_train, y_train)\n",
    "\n",
    "print(\"Training Logistic Regression...\")\n",
    "log_model.fit(X_train, y_train)\n",
    "\n",
    "print(\"Training Perceptron...\")\n",
    "perceptron_model.fit(X_train, y_train)\n",
    "\n",
    "print(\"Training DNN...\")\n",
    "dnn_model.fit(X_train, y_train)\n",
    "\n",
    "# Save the trained models\n",
    "joblib.dump(svm_model, 'svm_model.pkl')\n",
    "joblib.dump(log_model, 'log_model.pkl')\n",
    "joblib.dump(perceptron_model, 'perceptron_model.pkl')\n",
    "joblib.dump(dnn_model, 'dnn_model.pkl')\n",
    "\n",
    "# Evaluation function\n",
    "def evaluate(model, name):\n",
    "    y_pred = model.predict(X_test)\n",
    "    if hasattr(model, \"predict_proba\"):\n",
    "        y_proba = model.predict_proba(X_test)[:, 1]\n",
    "    else:\n",
    "        y_proba = y_pred\n",
    "\n",
    "    print(f\"\\n{name} Evaluation:\")\n",
    "    print(f\"Accuracy : {accuracy_score(y_test, y_pred):.4f}\")\n",
    "    print(f\"Precision: {precision_score(y_test, y_pred):.4f}\")\n",
    "    print(f\"Recall   : {recall_score(y_test, y_pred):.4f}\")\n",
    "    print(f\"F1-Score : {f1_score(y_test, y_pred):.4f}\")\n",
    "    try:\n",
    "        print(f\"AUC-ROC  : {roc_auc_score(y_test, y_proba):.4f}\")\n",
    "    except:\n",
    "        print(\"AUC-ROC  : N/A\")\n",
    "\n",
    "# Evaluate the models\n",
    "evaluate(svm_model, \"SVM\")\n",
    "evaluate(log_model, \"Logistic Regression\")\n",
    "evaluate(perceptron_model, \"Perceptron\")\n",
    "evaluate(dnn_model, \"Deep Neural Network\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
